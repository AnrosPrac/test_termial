"""
AI-Generated Code Detection
Identifies statistical patterns unique to AI-written code

Detection signals:
- Comment verbosity and style
- Variable naming patterns  
- Code organization
- Library usage patterns
- Entropy analysis
"""

from typing import Dict, Tuple
import re
from collections import Counter
import math


class AIDetector:
    """Detect if code was likely generated by AI"""
    
    # AI code "tells" - patterns seen in AI-generated code
    AI_COMMENT_PATTERNS = [
        r'#\s*(Step \d+|First|Then|Next|Finally)',
        r'//\s*(Step \d+|First|Then|Next|Finally)',
        r'""".*?"""',  # Excessive docstrings
        r"'''.*?'''",
    ]
    
    AI_VARIABLE_PATTERNS = [
        r'\b(temp|result|data|value|item|element)\d*\b',
        r'\b(input|output)_\w+\b',
        r'\b(my|the|this|current)_\w+\b',
    ]
    
    def __init__(self):
        pass
    
    async def analyze(
        self,
        code: str,
        language: str
    ) -> Tuple[float, Dict]:
        """
        Analyze code for AI-generation indicators
        
        Returns:
            (ai_probability, details_dict)
        """
        try:
            features = self._extract_features(code, language)
            
            # Calculate AI probability from features
            ai_probability = self._calculate_ai_probability(features)
            
            details = {
                "comment_ratio": features['comment_ratio'],
                "verbose_comments": features['verbose_comments'],
                "ai_variable_count": features['ai_variable_count'],
                "docstring_count": features['docstring_count'],
                "entropy": features['entropy'],
                "line_length_avg": features['avg_line_length'],
                "indicators": features['indicators']
            }
            
            return ai_probability, details
            
        except Exception as e:
            return 0.0, {"error": str(e)}
    
    def _extract_features(self, code: str, language: str) -> Dict:
        """Extract AI-detection features from code"""
        lines = code.split('\n')
        non_empty_lines = [l for l in lines if l.strip()]
        
        features = {}
        
        # 1. Comment analysis
        comment_lines = self._count_comment_lines(code, language)
        total_lines = len(non_empty_lines)
        features['comment_ratio'] = comment_lines / max(total_lines, 1)
        
        # 2. Verbose comment detection
        features['verbose_comments'] = self._count_verbose_comments(code)
        
        # 3. AI-style variable names
        features['ai_variable_count'] = self._count_ai_variables(code)
        
        # 4. Docstring count (Python)
        if language == 'python':
            features['docstring_count'] = len(re.findall(r'""".*?"""', code, re.DOTALL))
        else:
            features['docstring_count'] = 0
        
        # 5. Code entropy (randomness)
        features['entropy'] = self._calculate_entropy(code)
        
        # 6. Line length patterns
        features['avg_line_length'] = sum(len(l) for l in non_empty_lines) / max(len(non_empty_lines), 1)
        
        # 7. Specific AI indicators
        features['indicators'] = self._find_ai_indicators(code, language)
        
        return features
    
    def _count_comment_lines(self, code: str, language: str) -> int:
        """Count lines with comments"""
        if language == 'python':
            return len(re.findall(r'^\s*#', code, re.MULTILINE))
        else:
            single = len(re.findall(r'^\s*//', code, re.MULTILINE))
            multi = len(re.findall(r'/\*.*?\*/', code, re.DOTALL))
            return single + multi
    
    def _count_verbose_comments(self, code: str) -> int:
        """Count suspiciously verbose/structured comments"""
        count = 0
        
        for pattern in self.AI_COMMENT_PATTERNS:
            count += len(re.findall(pattern, code, re.IGNORECASE | re.DOTALL))
        
        # Long comments (>80 chars) are common in AI code
        long_comments = re.findall(r'#[^\n]{80,}|//[^\n]{80,}', code)
        count += len(long_comments)
        
        return count
    
    def _count_ai_variables(self, code: str) -> int:
        """Count AI-style variable names"""
        count = 0
        
        for pattern in self.AI_VARIABLE_PATTERNS:
            matches = re.findall(pattern, code, re.IGNORECASE)
            count += len(matches)
        
        return count
    
    def _calculate_entropy(self, code: str) -> float:
        """
        Calculate Shannon entropy of code
        AI code tends to have different entropy than human code
        """
        if not code:
            return 0.0
        
        # Count character frequencies
        counter = Counter(code)
        total = len(code)
        
        # Calculate Shannon entropy
        entropy = 0.0
        for count in counter.values():
            probability = count / total
            if probability > 0:
                entropy -= probability * math.log2(probability)
        
        return entropy
    
    def _find_ai_indicators(self, code: str, language: str) -> list:
        """Find specific AI-generation indicators"""
        indicators = []
        
        # 1. Perfect PEP 8 style (overly perfect formatting)
        if language == 'python':
            if re.search(r'^\s{4}', code, re.MULTILINE):  # Consistent 4-space indent
                indicators.append("Consistent 4-space indentation")
        
        # 2. Type hints everywhere (Python)
        if language == 'python':
            type_hints = len(re.findall(r'->\s*\w+:', code))
            if type_hints > 0:
                indicators.append(f"Type hints usage ({type_hints})")
        
        # 3. Excessive imports
        import_count = len(re.findall(r'^(import|from\s+\w+\s+import)', code, re.MULTILINE))
        if import_count > 5:
            indicators.append(f"Many imports ({import_count})")
        
        # 4. Function decomposition (AI loves small functions)
        func_count = len(re.findall(r'\bdef\s+\w+|^\w+\s+\w+\s*\([^)]*\)\s*\{', code, re.MULTILINE))
        if func_count > 5:
            indicators.append(f"Many functions ({func_count})")
        
        # 5. Descriptive function names (>15 chars)
        long_names = re.findall(r'\bdef\s+(\w{15,})|^\w+\s+(\w{15,})\s*\(', code, re.MULTILINE)
        if long_names:
            indicators.append(f"Very descriptive names ({len(long_names)})")
        
        # 6. try-except everywhere (AI is cautious)
        if language == 'python':
            try_count = len(re.findall(r'\btry:', code))
            if try_count > 2:
                indicators.append(f"Excessive error handling ({try_count})")
        
        # 7. Comments explaining every step
        step_comments = len(re.findall(r'#.*?(step|first|then|next|finally)', code, re.IGNORECASE))
        if step_comments > 3:
            indicators.append(f"Step-by-step comments ({step_comments})")
        
        return indicators
    
    def _calculate_ai_probability(self, features: Dict) -> float:
        """
        Calculate AI probability from features using weighted scoring
        """
        score = 0.0
        
        # 1. High comment ratio (AI loves comments)
        if features['comment_ratio'] > 0.3:
            score += 0.2
        elif features['comment_ratio'] > 0.2:
            score += 0.1
        
        # 2. Verbose comments
        if features['verbose_comments'] > 5:
            score += 0.25
        elif features['verbose_comments'] > 2:
            score += 0.15
        
        # 3. AI variable names
        if features['ai_variable_count'] > 10:
            score += 0.2
        elif features['ai_variable_count'] > 5:
            score += 0.1
        
        # 4. Docstrings (Python)
        if features['docstring_count'] > 3:
            score += 0.15
        elif features['docstring_count'] > 1:
            score += 0.08
        
        # 5. Entropy (AI code has predictable entropy range)
        entropy = features['entropy']
        if 4.0 < entropy < 5.5:  # Typical AI code entropy
            score += 0.1
        
        # 6. Line length (AI tends to have consistent line lengths)
        avg_len = features['avg_line_length']
        if 40 < avg_len < 80:  # AI "sweet spot"
            score += 0.05
        
        # 7. Number of indicators
        indicator_count = len(features['indicators'])
        if indicator_count > 5:
            score += 0.15
        elif indicator_count > 3:
            score += 0.08
        
        # Normalize to 0-1
        return min(score, 1.0)


class AIPatternDatabase:
    """
    Database of known AI code patterns
    Can be trained on labeled datasets
    """
    
    def __init__(self):
        # Common AI library imports
        self.ai_imports = {
            'python': [
                'import numpy as np',
                'import pandas as pd',
                'from typing import',
                'from dataclasses import dataclass',
            ],
            'c': [
                '#include <stdio.h>',
                '#include <stdlib.h>',
                '#include <string.h>',
            ],
            'cpp': [
                '#include <iostream>',
                '#include <vector>',
                '#include <algorithm>',
                'using namespace std;',
            ]
        }
        
        # Common AI comment templates
        self.ai_comments = [
            "Initialize variables",
            "Check if input is valid",
            "Handle edge cases",
            "Return the result",
            "Helper function to",
            "Main logic goes here",
        ]
    
    def check_pattern_match(self, code: str, language: str) -> Dict:
        """Check for known AI patterns"""
        matches = {
            'import_matches': 0,
            'comment_matches': 0,
            'patterns_found': []
        }
        
        # Check imports
        if language in self.ai_imports:
            for import_pattern in self.ai_imports[language]:
                if import_pattern in code:
                    matches['import_matches'] += 1
                    matches['patterns_found'].append(f"Import: {import_pattern}")
        
        # Check comments
        for comment_template in self.ai_comments:
            if comment_template.lower() in code.lower():
                matches['comment_matches'] += 1
                matches['patterns_found'].append(f"Comment: {comment_template}")
        
        return matches
